# -*- coding: utf-8 -*-
"""player reidentification model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_roF3Kw-1N9Sr6B2crHn66-in3hBX4tA
"""

# ✅ Install dependencies
!pip install -q ultralytics git+https://github.com/openai/CLIP.git opencv-python-headless faiss-cpu

# ✅ Imports
import cv2
import torch
import clip
import numpy as np
import pandas as pd
from ultralytics import YOLO
from PIL import Image
from sklearn.metrics.pairwise import cosine_similarity
from scipy.optimize import linear_sum_assignment

# ✅ Setup
device = "cuda" if torch.cuda.is_available() else "cpu"
model = YOLO("best.pt")
clip_model, clip_preprocess = clip.load("ViT-B/32", device=device)
clip_model.eval()

# ✅ Resize helper
def resize_frame(frame, size=(640, 384)):
    return cv2.resize(frame, size)

# ✅ Embedding extractor
def get_embeddings(frame, boxes):
    embeddings = []
    valid_boxes = []
    for box in boxes:
        x1, y1, x2, y2 = map(int, box)
        crop = frame[y1:y2, x1:x2]
        if crop.shape[0] < 10 or crop.shape[1] < 10:
            continue
        crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
        crop_tensor = clip_preprocess(crop_pil).unsqueeze(0).to(device)
        with torch.no_grad():
            emb = clip_model.encode_image(crop_tensor).cpu().numpy()
            emb = emb / np.linalg.norm(emb)
            embeddings.append(emb)
            valid_boxes.append(box)
    if embeddings:
        return np.vstack(embeddings), valid_boxes
    else:
        return np.empty((0, 512)), []

def detect_players(frame):
    resized = resize_frame(frame)
    results = model(resized)[0]
    boxes = [box.xyxy[0].cpu().numpy() for box in results.boxes if int(box.cls) == 0]

    # Map back to original scale
    scale_x = frame.shape[1] / 640
    scale_y = frame.shape[0] / 384
    scaled_boxes = [[x1*scale_x, y1*scale_y, x2*scale_x, y2*scale_y] for (x1,y1,x2,y2) in boxes]
    return scaled_boxes

def match_players(emb1, emb2):
    if len(emb1) == 0 or len(emb2) == 0:
        return [], []
    sim_matrix = cosine_similarity(emb1, emb2)
    row_idx, col_idx = linear_sum_assignment(1 - sim_matrix)
    return row_idx, col_idx

# ✅ Load videos
tacticam = cv2.VideoCapture("tacticam.mp4")
broadcast = cv2.VideoCapture("broadcast.mp4")

fps = int(tacticam.get(cv2.CAP_PROP_FPS))
out_width = int(tacticam.get(cv2.CAP_PROP_FRAME_WIDTH)) + int(broadcast.get(cv2.CAP_PROP_FRAME_WIDTH))
out_height = max(int(tacticam.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(broadcast.get(cv2.CAP_PROP_FRAME_HEIGHT)))

# ✅ Video writer and CSV logger
out = cv2.VideoWriter("matched_output.mp4", cv2.VideoWriter_fourcc(*'mp4v'), fps, (out_width, out_height))
csv_rows = []

# ✅ Player ID memory
next_id = 0
embedding_bank = []
id_bank = []

# ✅ Preload broadcast frames and embeddings
broadcast_frames = []
while True:
    ret, b_frame = broadcast.read()
    if not ret:
        break
    b_boxes = detect_players(b_frame)
    b_embeds, b_valid_boxes = get_embeddings(b_frame, b_boxes)
    broadcast_frames.append((b_frame, b_valid_boxes, b_embeds))
broadcast.release()

# ✅ Process tacticam frames
frame_skip = 5
frame_no = 0
while True:
    ret, t_frame = tacticam.read()
    if not ret:
        break
    if frame_no % frame_skip != 0:
        frame_no += 1
        continue

    t_boxes = detect_players(t_frame)
    t_embeds, t_valid_boxes = get_embeddings(t_frame, t_boxes)

    if len(t_embeds) == 0:
        frame_no += 1
        continue

    # Find best matching broadcast frame
    best_match = None
    best_row_idx, best_col_idx = [], []
    max_matches = 0
    for b_frame, b_boxes, b_embeds in broadcast_frames:
        row_idx, col_idx = match_players(t_embeds, b_embeds)
        if len(row_idx) > max_matches:
            max_matches = len(row_idx)
            best_match = (b_frame.copy(), b_boxes, b_embeds, row_idx, col_idx)

    if best_match is None:
        frame_no += 1
        continue

    b_frame, b_boxes, b_embeds, row_idx, col_idx = best_match
    ids = [-1] * len(t_valid_boxes)

    for i, j in zip(row_idx, col_idx):
        t_vec = t_embeds[i]
        b_vec = b_embeds[j]

        # Match to existing ID
        best_sim, best_id = 0, None
        for idx, emb in enumerate(embedding_bank):
            sim = cosine_similarity(t_vec.reshape(1, -1), emb.reshape(1, -1))[0][0]
            if sim > 0.92 and sim > best_sim:
                best_sim = sim
                best_id = id_bank[idx]

        if best_id is None:
            best_id = next_id
            embedding_bank.append(t_vec)
            id_bank.append(next_id)
            next_id += 1

        ids[i] = best_id

        # Draw on tacticam
        x1, y1, x2, y2 = map(int, t_valid_boxes[i])
        cv2.rectangle(t_frame, (x1, y1), (x2, y2), (0,255,0), 2)
        cv2.putText(t_frame, f"ID {best_id}", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)

        # Draw on broadcast
        x1, y1, x2, y2 = map(int, b_boxes[j])
        cv2.rectangle(b_frame, (x1, y1), (x2, y2), (0,0,255), 2)
        cv2.putText(b_frame, f"ID {best_id}", (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)

        # Log
        csv_rows.append([frame_no, best_id, "tacticam", *map(int, t_valid_boxes[i])])
        csv_rows.append([frame_no, best_id, "broadcast", *map(int, b_boxes[j])])

    combined = np.hstack((t_frame, b_frame))
    out.write(combined)
    frame_no += 1

# ✅ Save CSV
df = pd.DataFrame(csv_rows, columns=["frame_no", "player_id", "camera", "x1", "y1", "x2", "y2"])
df.to_csv("player_tracking.csv", index=False)
tacticam.release()
out.release()

print("✅ Done! Output saved as 'matched_output.mp4' and 'player_tracking.csv'")